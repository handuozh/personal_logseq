- #related
  - [[kernel ridge regression]]
  - [[rvfl]]
- ELM就是在前向神经网络feedforward neural networks中，隐层和输入层之间采用随机权值，在最后输出层利用伪逆或者添加正则项的方法求解输出权值，从而达到回归或者分类的目的
  - 随机投影（random projection）＋线性模型（linear classifier）
  - 通过带有非线性的足够多的M个hidden node来构造一个相对于训练数据量N而言足够大的MxN的矩阵，保证矩阵满秩（按照概率）
  - 寻找此矩阵的一个子空间来拟合目标函数。
  -
- 缺点
  - 没有深度导致需要更多的参数来拟合复杂的函数，单层的随机投影很难提取复杂数据的特征
    - 深度学习为什么强调深度？因为深层的表达可以用较少的参数拟合更复杂的函数，svm等算法也致力于使用较少的参数来表达复杂模型。而ELM反其道而行之，用更多的参数来拟合一个较为简单的函数，比如mnist99%识别率的那篇，隐层节点数高达15000！其哲学就是蒙上15000次，总会碰到一些好点的pattern。在测试时，如果要推测一个数字是几，要做个700*15000大小的矩阵乘法，这在实际应用中是不可接受的。
  -