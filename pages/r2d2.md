---
title: R2D2
public: true
---

## ËØÑÂàÜ [[4üíóÔ∏è]]
## Meta Data
:PROPERTIES:
:heading: true
:END:
### #title R2D2: Repeatable and Reliable Detector and Descriptor, 2019
### code https://github.com/naver/r2d2

### #topic #repeatability #reliability #keypoint #[[Average-precision (AP)]]  #Detection-and-describe
## [[repeatability]]:: Salient region. Repeatable regions are not necessarily discriminative and can, therefore, lead to select sub-optimal keypoints. (Like repetitive pattern)
## [[reliability]]:: Descriptors should be learned only in regions for which matching can be performed with high confidence.

## Build upon the basis of [[D2-Net]] 
### Decouple [[repeatability]] and  [[reliability]] to learn 2 confidence maps.

## 1. Method
:PROPERTIES:
:heading: true
:END:
### ^^Backbone^^ is [[L2-Net]] with two updates:
#### subsampling replaced by [[dilated conv]]. (^^Preserve input resolution^^)

#### the last $$ 8\times8$$ conv layer replaced by 3 successive $$ 2\times 2 $$ conv layers.

### The 128-d output tensor serves as input to:
#### a $$\mathcal{l}_2$$-[[normalization]] layer to get per-pixel patch descriptor $$\mathbf{X}$$.
#### an element-wise square operation followed by addition $$1\times1$$ cov layer and a softmax to get the repeatability map $\mathbf{S}$.
#### an identical second branch to get the reliability map $$\mathbf{R}$$.

### [[https://cdn.logseq.com/%2F0602f0ea-7667-4dfc-a07c-0cc047d72aaa2020_11_25_r2d2_overview.png?Expires=4759877379&Signature=kTVGt1iDp8AWA1wyleR-yI4qJW7ly-sNWhA7Qf3xN0yOi0kOoepb3AC5VrzIC8UTNOongN2o-AcGY7SXeyjp-MDNUa705KD52AGx0zNkkii3TwG8zKSzXjXhOu5Jop7Z5SXMV09A-Qvp2t-Rx9yhTV~VxUSplxjnZvGOdplqvSXyVyn-QaSCOQzRA1UuEGj8JGcdD3evAgco~TbfV~Y6ifcpRbal~Y~o4z83T20Brrf4a9uDvEgxyL3Ii2cB4ChVm6Zr67nnsnO-7KoJks9~GiAqRFZZHiNHH66ivhOjyxIfHivIZX~6G1~E5T3pzGAGJpal3L1G8yjYOBK~jwponQ__&Key-Pair-Id=APKAJE5CCD6X7MP6PTEA][2020_11_25_r2d2_overview.png]]
### 1.1 Learning [[repeatability]]  <->  [[Keypoint Extraction]]
#### As observed in [[Superpoint]] and [[LIFT]], keypoint [[repeatability]] cannot be tackled by standard supervised training.

#### The paper treats repeatability as [[Self-supervised]] task. Positions of ^^local^^ maxima in $$\mathbf{S}$$ are covariant to natural image transformations like viewpoint or illumination changes.
#### Let $I \rightarrow U \leftarrow I^{\prime}$  be two images of the same scene with GT correspondences $U\in{\mathbb{R}^{H\times W\times 2}}$ .
#### Let  $\mathbf{S}$ and $\mathbf{S}^{\prime}$be the repeatability maps, $\mathbf{S}_U$ and $\mathbf{S}_U^{\prime}$ are warped according to $U$.
####
```python
sali1, sali2 = repeatability
  grid = FullSampler._aflow_to_grid(aflow)
  // Warp S2 according to U to S2_u
  sali2 = F.grid_sample(sali2, grid, mode='bilinear',  padding_mode='border')
```
#### Enforce all local maxima in $\mathbf{S}$ correspond to $\mathbf{S}_U^{\prime}$ by maximizing [[Cosine Similarity]]. Locally we average [[Cosine Similarity]] over small overlapping patches $P=\{p\}$ that has all $N  \times N$ in $\{1, \cdots, W\} \times \{ 1, \cdots, H\}$ and define loss:
##### (1)   $$  \mathcal{L}_{cosim}(I, I^{\prime}, U)=1-\frac{1}{|\mathcal{P}|}\sum\limits_{p\in{\mathcal{P}}} cosim\left(\mathbf{S}[p], \mathbf{S}_U^{\prime}[p]\right)$$  
where $$ \mathbf{S}_U^{\prime} [p]\in{\mathbb{R}^{N^2}} $$  denotes flattened $$ N\times N $$ patch $$ p $$ extracted from $$ \mathbf{S} $$ .

##### Code of $$ N\times N$$  patches:
######
```python
patches = nn.Unfold(N, padding=0, stride=N // 2)
```
##### Then flatten and normalize the extracted patches:
######
```python
 # flatten
patches = self.patches(sal).transpose(1, 2)
 # norm
patches = F.normalize(patches, p=2, dim=2)
```
#### To avoid $$ \mathcal{L}_{cosim} $$ can be **minimized trivially by having maps constant**, we employ a second loss function to maximize the __local__ ^^peakiness^^ of the repeatability map:
##### (2)    $$ \mathcal{L}_{peaky}(I)=1-\frac{1}{|\mathcal{P}|}\sum\limits_{p\in{\mathcal{P}}} \left( \max\limits_{(i,j)\in p} \mathbf{S}_{ij}, \underset{(i,j) \in p}{mean} \mathbf{S}_{ij}\right) $$  
**max** and **mean** here refer to __MaxPool2d__ and __AvgPool2d__.
###### We can choose [Spatial Frequency](Spatial-Frequency.md) of local maxima by varying patch size $$ N $$ .

#### Weighted sum:
##### (3)    $$ \mathcal{L}_{rep}(I, I^{\prime}, U) = \mathcal{L}_{cosim}(I, I^{\prime}, U) + \frac{1}{2}\left( \mathcal{L}_{peaky}(I) + \mathcal{L}_{peaky}(I^{\prime})   \right) $$ .

### 1.2 Learning [[reliability]] <-> [[Descriptor Matching]]
#### {{{embed ((5fbf59b6-8148-4ff9-8d56-d9916c2c9189)) }}}
#### **Goal**: Computes ^^dense^^ local descriptors $\mathbf{X}$ and heatmap $\mathbf{R}$. Learn to choose between making descriptors as ^^discriminative^^ as possible, spare efforts on uninformative regions like sky.
#### ^^Previous work:^^ [[Pn-net]], [[Matchnet]], [[ContextDesc]], [[L2-Net]], [[Sosnet]] . They cast [[Descriptor Matching]] as [[metric-learning]] problem. #related
#### Each pixel $$ (ij) $$ from $$ I $$ is the center of a $$ M\times M $$ patch $$ p_{ij} $$ with descriptor $$ \mathbf{X}_{ij} $$ to compare with descriptors $$ \{ \mathbf{X}^{\prime}_{uv}\} $$ of all the other patches in the second image $$ I^{\prime} $$.

#### Knowing GT correspondence mapping $$ U $$, we estimate reliability of patch $p_{ij}$ using  [[Average-precision (AP)]] .
##### {{{embed ((5fbf59b6-d9a1-4ecf-bd22-a9f151e36be6)) }}}
##### We need to maximize AP by optimizing differentibale approximation of the AP as $$ \widetilde{AP} $$.

##### Training consists in maximizing the AP computed for each of the $$ B $$ patches $$ \{p_{ij}\} $$ in the batch:
(4)    $$ \mathcal{L}_{AP} = \frac{1}{B} \sum\limits_{ij} 1 - \widetilde{AP}(p_{ij}) $$.
######
```python
class PixelAPLoss(nn.Module):
  def __init__(self, sampler, nq=20):
    nn.Module.__init__(self)
    self.aploss = APLoss(nq, min=0, max=1, euc=False)
    self.name = 'pixAP'
    self.sampler = sampler
  def loss_from_ap(self, ap, rel):
  	return 1 - ap
  def forward(self, descriptors, aflow, **kw):
  	# subsample things
    scores, gt, msk, qconf = self.sampler(descriptors, kw.get('reliability'), aflow)
    # compute pixel-wise AP
    n = qconf.numel()
    if n == 0:
    	return 0
    scores, gt = scores.view(n, -1), gt.view(n, -1)
    ap = self.aploss(scores, gt).view(msk.shape)
    pixel_loss = self.loss_from_ap(ap, qconf)
    loss = pixel_loss[msk].mean()
    return loss
```
#### Local descriptors are extracted at ^^each^^ pixel with different _interestingness_.

#### To spare the nework in wasting efforts on undistinctive regions, also train a ^^pixel-wise confidence^^ $\mathbf{R}_{ij}$ that this pixel is going to have a good AP.
##### (5)     $$ \mathcal{L}_{AP,\mathbf{R}} = \frac{1}{B} \sum\limits_{ij} 1 - \widetilde{AP}(p_{ij})\mathbf{R}_{ij} + \kappa(1-\mathbf{R}_{ij}) $$

##### where $\kappa \in [0,1]$ is a hyperparameter of AP threshold above which a patch is considered reliable.
##### Relationship between estimated AP and reliability. We use $\kappa=0.5$
##### [[https://cdn.logseq.com/%2F0602f0ea-7667-4dfc-a07c-0cc047d72aaa2020_11_26_reliab.png?Expires=4759975155&Signature=k8FJ7nwPIAT7jndxbNSX3HL8pJ1FcAWenKXJpWAe1uI65BSZtnbM48afOgi0TI4O0~AuAl0dkCifAAyENuUIhdakj77fihVTY5nRSQiHWXF744lbcbT2sz8lRSmQr28TzzVFXPs9oRu5wohfxAGbSAT2ZXGJof~dXqEM9iHyobKA43dwhJw3ycJVKeGx0vTmjC5sDoQiIpNtYa4h13ZK8OrfHVFexeB2jUZbUdvsMzPyQ07~1mbums2o~vb2cEjKNnJcy7IjXZ3J~rGFP71tjHc2-SBDlKc0QV26c~hFat-1we8VwtUY6uemQKQZ2cI5BWGcDOmCdPzgibV8sSfM8A__&Key-Pair-Id=APKAJE5CCD6X7MP6PTEA][2020_11_26_reliab.png]]
##### Similar idea [Self-supervised-features](Self-supervised-features.md) uses triplet loss without using interpretable threshold $$ \kappa$$ . The comparison can be seen below:
###### ((5fbf59b6-f639-4d14-8bf2-780ef2f3b88f))
#####
```python
class ReliabilityLoss(pixelAPLoss):
  def __init__(self, sampler, base=0.5, **kw):
    PixelAPLoss.__init__(self, sampler, **kw)
    assert 0 <= base < 1
    self.base = base
    self.name = 'reliability'
  def loss_from_ap(self, ap, rel):
  	return 1 - ap * rel - (1 - rel) * self.base
```
## 2. Training
:PROPERTIES:
:heading: true
:END:
### 2.1 Training Data
#### Three sources of data
##### distractors from a retrieval database (random web images). Build [[Synthetic Image Pairs]] by applying random transformations (homography and color jittering)

##### images from Aachen dataset, also synthetic pairs

##### Pairs of nearby views from Aachen dataset by obtaining a pseudo GT with optical flow.

### 2.2 GT correspondences
#### As [[D2-Net]] and [[Lf-net]] used, use points verified by **SfM** (with sufficient overlap to calculate fundamental matrix.) 

#### Use [[EpicFlow]] to generate optical flow. Enhance it by adding epipolar constraints in [[DeepMatching]] to output semi-sparse matches.

### 2.3 Sampling issues for AP loss
#### Subsample "query" patches in the first image on regular grid $8\times 8$ pixels. As optical flow not perfect, define a single positive per query patch $p_{ij}$ in the second image as the one with the most similar descriptor within radius of 3 pixels from ground truth position $U_{ij}$.
#### TODO NghSampler2

## 3. Experiments
:PROPERTIES:
:heading: true
:END:
### 3.1 Datasets and metrics
#### Evaluate on [[HPatches Dataset]]. 

#### [[repeatability]] compute the score for a pair of images a number of point correspondences divided by a minimum number of keypoint detections. Average score over all pairs.

#### [[M-score]]:: Matching score. The average ratio between GT correspondences recovered and the total number of estimated features within the shared viewpoint region when matching back and forth.
#### [[MMA]]:: Mean matching accuracy. The average percentage of correct matches in image pair considering multiple pixel error thresholds.
### 3.2 Parameter study
#### Impact of $N$. ^^It controls keypoint number^^ as the loss ideally encourages network to output a single local maxima per window $N\times N$.
##### Models trained with large $N$ outperform those with lower $N$ when retained keypoint number $K$ is low. So the trade-off is $N=16$  and $K=5000$.
#### **Impact of separate reliability and repeatability.**  

#### 

## Repeatable regions are not necessarily discriminative and can, therefore, lead to select suboptimal keypoints. Furthermore, we claim that descriptors should be learned only in regions for which matching can be performed with high confidence.