---
title: batchnorm
---

- ![21⁄03⁄12⁄15-25.png](../assets/pages_batchnorm_1615533997174_0.png)
- batch norm 和 [[layer normalization]] 对比
    - ![image.png](../assets/pages_batchnorm_1615534217431_0.png)
    - BN强行让一个batch的数据的某个channel的$\mu=0,\sigma=1$
    - layer normalization让一个数据的所有channel的$\mu=0,\sigma=1$
    -